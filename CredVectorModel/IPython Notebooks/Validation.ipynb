{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import _pickle as pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Helpers.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (sentenceEncoder): LSTMSentenceEncoderParallel(\n",
       "    (embeddings): Embedding(400004, 100, padding_idx=400003)\n",
       "    (sentenceEncoder): LSTM(100, 150, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (sourceBias): SourceBiasParallel(\n",
       "    (trans): Linear(in_features=300, out_features=300, bias=True)\n",
       "    (source_embeddings): Embedding(210381, 300)\n",
       "  )\n",
       "  (documentEncoder): LSTM(300, 300, batch_first=True, bidirectional=True)\n",
       "  (documentAttention): Attention(\n",
       "    (trans): Bilinear(in1_features=600, in2_features=300, out_features=1, bias=True)\n",
       "  )\n",
       "  (biasMLP): MLP(\n",
       "    (layer1): Linear(in_features=600, out_features=300, bias=True)\n",
       "    (layer2): Linear(in_features=300, out_features=5, bias=True)\n",
       "  )\n",
       "  (truthMLP): MLP(\n",
       "    (layer1): Linear(in_features=600, out_features=300, bias=True)\n",
       "    (layer2): Linear(in_features=300, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(NO_URLS, EMB)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('parameters_1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = pickle.load(open('validation_0', 'rb+'))\n",
    "#validation_data.extend(pickle.load(open('validation_1', 'rb+')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = validation_data\n",
    "lines, pad_lengths = pad_data(raw_data)\n",
    "class_ = [class_mapping[row[-1]] for row in raw_data]\n",
    "truth = [int(row[-2]) for row in raw_data]\n",
    "lengths = [[] for _ in range(90)]\n",
    "for i, j in enumerate(lines):\n",
    "    if not len(j) == 0:\n",
    "        lengths[len(j) - 1].append(i)\n",
    "urls = [i[1][0:90] for i in raw_data]\n",
    "batches = []\n",
    "for unit in lengths:\n",
    "    for i in range(0, len(unit), batch_size):\n",
    "        batches.append(unit[i:i+batch_size])\n",
    "titles = pad_titles(raw_data)\n",
    "random.shuffle(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bias_tp, bias_tn, bias_fp, bias_fn = torch.cuda.FloatTensor([0]), torch.cuda.FloatTensor([0]), torch.cuda.FloatTensor([0]), torch.cuda.FloatTensor([0])\n",
    "truth_tp, truth_tn, truth_fp, truth_fn = torch.cuda.FloatTensor([0]), torch.cuda.FloatTensor([0]), torch.cuda.FloatTensor([0]), torch.cuda.FloatTensor([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bias = []\n",
    "p_bias = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5021\r"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for batch in batches:\n",
    "        if len(batch) == 20:\n",
    "            input_ = torch.cuda.LongTensor([lines[i] for i in batch])\n",
    "            urls_ = torch.cuda.LongTensor([urls[i] for i in batch])\n",
    "            titles_ = torch.cuda.LongTensor([titles[i] for i in batch])\n",
    "            truth_ = torch.cuda.FloatTensor([[truth[i]] for i in batch])\n",
    "            bias_ = torch.max(torch.cuda.FloatTensor([class_[i] for i in batch]), dim=1)[1]\n",
    "            pbias, ptruth = model(input_, urls_, titles_)\n",
    "            \n",
    "            truth_tp += torch.sum(ptruth.gt(.5) * truth_.gt(0)).float()\n",
    "            truth_tn += torch.sum(ptruth.le(.5) * truth_.le(0)).float()\n",
    "            truth_fp += torch.sum(ptruth.gt(.5) * truth_.le(0)).float()\n",
    "            truth_fn += torch.sum(ptruth.le(.5) * truth_.gt(0)).float()\n",
    "            \n",
    "            pbias = torch.max(pbias, dim=1)[1]\n",
    "            bias.extend(np.array(bias_.cpu().data))\n",
    "            p_bias.extend(np.array(pbias.cpu().data))\n",
    "        print(batches.index(batch), end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([51760.], device='cuda:0'),\n",
       " tensor([42668.], device='cuda:0'),\n",
       " tensor([56489.], device='cuda:0'),\n",
       " tensor([46629.], device='cuda:0'))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_tp, truth_tn, truth_fp, truth_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5010], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "precision = truth_tp / (truth_tp + truth_fp)\n",
    "recall = truth_tp / (truth_tp + truth_fn)\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bias = np.array(bias)\n",
    "p_bias = np.array(p_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = np.zeros((5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, j in zip(bias, p_bias):\n",
    "    confusion_matrix[i][j] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11153.,  2760.,  1352.,   230.,  9089.],\n",
       "       [ 8425.,  6720.,  1485.,   176.,  1288.],\n",
       "       [ 8884.,  6932.,  1456.,   168.,  2373.],\n",
       "       [ 7442.,  2151.,   330.,    51.,  1670.],\n",
       "       [ 9995.,  2437.,   430.,   531., 11192.]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
